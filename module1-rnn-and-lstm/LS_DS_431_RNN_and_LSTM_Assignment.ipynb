{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanCampos11/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8ih8i_Yvre",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "kh5cfkXVYvrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "zBXBJxdzYvri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "L5doYy1KYvrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "34c77380-3a57-49c9-b61b-a6e98632e316"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyMmu1xnlKtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0f79cbc-d0f4-4d74-da2e-98460e7e5c7a"
      },
      "source": [
        "data = df_toc['text'].values\n",
        "len(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c02n5XS7kjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# # Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKzk-cJQeANl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d270e16-4f2b-4653-c3f9-26749b40b086"
      },
      "source": [
        "maxlen = 80\n",
        "step = 5\n",
        "max_features = 20000\n",
        "batch_size = 32\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  3041153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRWnkW_2A0vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_size = 20000\n",
        "sequences = [\n",
        "    sequences[i] for i in sorted(random.sample(range(len(sequences)), sample_size))\n",
        "]\n",
        "# sequences = random.sample(sequences,2000000)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzY4LEkuuia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QequjCwax0F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSbziohxzLTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sequences in enumerate(sequences):\n",
        "    for t, char in enumerate(sequences):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbSblnhzRi6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a7f173e-48d6-4f9b-9598-1998e1dea823"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCpGCIJjQnGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bV5Bi23QnI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihywh08PQnLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD45JvI7uulW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdThFl2euuqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjMSZGVoz_rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    # Random prompt\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        # Predict the next step (character)\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSGNDwOcz_t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3dfb82e7-3d70-4a84-a07b-69445e985663"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 3.2353\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"tur’d\n",
            "To try your taking of a false report, which hath\n",
            "Honour’d with confirmat\"\n",
            "tur’d\n",
            "To try your taking of a false report, which hath\n",
            " ue .e qhee e\n",
            "e\n",
            ".cl\n",
            "ey lthd t,mLlu\n",
            "o\n",
            "t\n",
            "uh\n",
            "Eohseruoead tS,dishru ed agn mee den, tts Y.er fem a vsSgf Sdahaea  se  h  fedOOgasTltpo esaauE   aehh.D rhehe\n",
            "Rdhare hedr \n",
            "ro ee\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.2353\n",
            "Epoch 2/10\n",
            "618/625 [============================>.] - ETA: 0s - loss: 3.1839\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"They bow\n",
            " severall wayes: then advance and stand.]\n",
            "\n",
            "ARCITE.\n",
            "And me my love! \"\n",
            "They bow\n",
            " severall wayes: then advance and stand.]\n",
            "\n",
            "ARCITE.\n",
            "And me my love! A\n",
            " u ositNSO tr.se s s edt  h  em ytuU sh  A c .l  br\n",
            ";ahe. TyhAry  nyly  e ahOR s  s ti,E u e f'HT EtR o\n",
            "euy,\n",
            "deie\n",
            "rApf\n",
            " weo eur mi hLv ueodertemce g sanu nardn  e  tlPmr al SOulrooisAoafOeel lt t a   o tir wudvD , n Fehreg \n",
            "]ltR wnnrh\n",
            "625/625 [==============================] - 16s 26ms/step - loss: 3.1843\n",
            "Epoch 3/10\n",
            "622/625 [============================>.] - ETA: 0s - loss: 3.1802\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"bstayning of my joy,\n",
            "Which breeds a deeper longing, cure their surfeit\n",
            "That cr\"\n",
            "bstayning of my joy,\n",
            "Which breeds a deeper longing, cure their surfeit\n",
            "y,w e  v tN T ai\n",
            "rl \n",
            "el  t,uemoaf l  ui  \n",
            "uhte,vtG o,antkcew  sTclhy ltNtRLhe\n",
            " esuhh a  i'egthtih,sa wsss thyOn lt ]daw \n",
            ",ngoiveuae h uidngalln adoe lao\n",
            "fhrteK hchB uwBt OiclR nwelyweK sasao\n",
            "aLah  \n",
            " ?elteN Tnito n etthg nLyr sReten  id  WCe efye eel.ide  e  W e\n",
            " \n",
            "\n",
            "bpu \n",
            "a n\n",
            "nonlmim  h lfN Abo\n",
            " d  htsOnQedt shu e\n",
            "y NRewIe \n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1793\n",
            "Epoch 4/10\n",
            "620/625 [============================>.] - ETA: 0s - loss: 3.1771\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"eyond your cell,\n",
            "There dancing up to th’ chins, that the foul lake\n",
            "O’erstunk t\"\n",
            "eyond your cell,\n",
            "There dancing up to th’ chins, that the foul lake\n",
            "b \n",
            "\n",
            "f td  oR hrt eyet  e  e so,o is rusrl\n",
            "tglsge\n",
            " tanr olteyeo u   o\n",
            "h y od wtt\n",
            "t ni\n",
            "edh s nmEeh;oo  rtegi  he\n",
            "udeO\n",
            "in  e D\n",
            " ,i  E Rpleittdo Uek,tueYemoaehre  ib\n",
            "ramcohmeNiOaioeentisn whl a dt annrue\n",
            "A aogrok .c sis EnaCeio  \n",
            ".hr dEI ea s e.  inw rt xsNStoLd w  s.k on\n",
            "ar iigcon  ym  e tsnad;\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1775\n",
            "Epoch 5/10\n",
            "623/625 [============================>.] - ETA: 0s - loss: 3.1738\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"ath wash’d thy sallow cheeks for Rosaline!\n",
            "How much salt water thrown away in w\"\n",
            "ath wash’d thy sallow cheeks for Rosaline!\n",
            "as no  s l .SaBf o'esekt    af e I  f s  gtu   Hoeha  yhd a n    n D efaiavvds hrd .sma ce   \n",
            "u t\n",
            "ghrdath   tt le s titdnLy  oh hc  a n nnY  ut ê  Ltr\n",
            "    s hd ispha Shmbraim,esa ti ssh\n",
            "siff o Olsma soi  e hh   dlu KhhuA o:f  , L\n",
            "leo\n",
            " \n",
            "\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 3.1735\n",
            "Epoch 6/10\n",
            "621/625 [============================>.] - ETA: 0s - loss: 3.1721\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"king hard all night, and\n",
            "    I will have more time to prepare me, or they shall\"\n",
            "king hard all night, and\n",
            "    f g  edni  Ee  soen O tetng\n",
            "teiena\" s  O c r e;oe dekor i e\n",
            "es.reso ihynader!isgsoodd a. r \n",
            "a    s p\n",
            "oAF'rvoskty m\n",
            "l tt . a\n",
            "smk\n",
            "anKw. enm ti mbbat loe  osaai\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1718\n",
            "Epoch 7/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 3.1698\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"t sound?\n",
            "  GARDINER. Not sound, I say.\n",
            "  CROMWELL. Would you were half so hone\"\n",
            "t sound?\n",
            "  GARDINER. Not sound, I say.\n",
            "i  ovi o nen   Rneav\n",
            "z? C \n",
            "irrih  n mKwu\n",
            "\n",
            "wr,:  NathtAaVEtI eerNy Wie\n",
            " dtkAten dltNt\n",
            "' JlkDhee ce a p i\n",
            "oo tdeo.a o n;s ehor\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1697\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 3.1668\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"he King's request that I would visit you,\n",
            "    Who grieves much for your weaknes\"\n",
            "he King's request that I would visit you,\n",
            "    Who grieves much for your weaknes    the o  eIts d   ry ftuxtc DnSl iEgcvudmWgBoi Sb; s\n",
            " t   ye h sdu tgdipelai  e. dhosn whwr ept  beIIl iena uos rnapylcl w dLagiAsttuhci  w umh\n",
            "ht\n",
            " stoua h rLi wto\n",
            " m ft iasnu   yWoIWf eats\n",
            " ip,as. .eai     nos  c  sklovuh \n",
            ",NautvsuladfhI rwna  rOsthe  mel f h ReeoeserE tr hll sd lf  \n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1668\n",
            "Epoch 9/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 3.1636\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"?\n",
            "\n",
            "CLOWN.\n",
            "He’s a soldier; and for one to say a soldier lies is stabbing.\n",
            "\n",
            "D\"\n",
            "?\n",
            "\n",
            "CLOWN.\n",
            "He’s a soldier; and for one to say a soldier lies is stabbing.\n",
            "\n",
            "s  fr  eo gytehwh   fg  tsi \n",
            ";i stode\n",
            " ge h\n",
            "kl w t\n",
            "daIvmx hThI ybuib\n",
            "  \n",
            ",i,c\n",
            "iEy eahvief yvteliert  s otRr uSneo \n",
            "tv\n",
            "e  a\n",
            "oaeef  lh\n",
            "nha  mynywli \n",
            " pemoRbll cdr fg ,,t\n",
            "625/625 [==============================] - 17s 27ms/step - loss: 3.1640\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 3.1592\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"aspect of mine\n",
            "Hath fear’d the valiant; by my love I swear\n",
            "The best-regarded v\"\n",
            "aspect of mine\n",
            "Hath fear’d the valiant; by my love I swear\n",
            "The best-regarded v  sr  .y. eel \n",
            "thsl rf eytue,mtacc bcw\n",
            "\n",
            "a mSeOsghva  rtn Lsvnbt weytd w;or d  u .s nNacmehE   yh et  t r l ste ?TwiIe;Oh emco.ucc ae d fnpt,l o\n",
            "\n",
            "aet  Alihkvssc Reo; \n",
            "orDSwrc. o!o  ,vwi Uaeoirk ,FttuTeaamfehEh\n",
            "asH fy irfofdd fo dN m  S' st\n",
            "w ol D\n",
            "625/625 [==============================] - 17s 28ms/step - loss: 3.1592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f98ed5f0be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uxliX2Jz_wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiS4nsgUz_yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIOdBc1z_0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-jiArCuus6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}