{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanCampos11/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8ih8i_Yvre",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "kh5cfkXVYvrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "zBXBJxdzYvri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "L5doYy1KYvrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2f0715ce-8efb-488d-db64-895a3f7aaf1a"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TanzRZhDDhte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6e943cfd-9722-4d68-eb8d-74b5e99a9b81"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = df_toc.load_data(num_words=max_features)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-588a500bc4c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_toc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'load_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DshwqvfJk9jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "\n",
        "for file in df_toc:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyMmu1xnlKtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da03e295-ba22-474e-b24c-76f15e5359de"
      },
      "source": [
        "data = df_toc['text'].values\n",
        "len(data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c02n5XS7kjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "# chars = random.sample(chars,300000)\n",
        "\n",
        "# # Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKzk-cJQeANl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c65d0512-0dbb-467f-948a-5e7ebeb11593"
      },
      "source": [
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  3041161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRWnkW_2A0vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = random.sample(sequences,200000)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzY4LEkuuia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QequjCwax0F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSbziohxzLTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sequences in enumerate(sequences):\n",
        "    for t, char in enumerate(sequences):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD45JvI7uulW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdThFl2euuqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjMSZGVoz_rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    # Random prompt\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        # Predict the next step (character)\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSGNDwOcz_t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6cdac07-b242-49ce-cb83-e9cd62952ed7"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6245/6250 [============================>.] - ETA: 0s - loss: 3.3284\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \", I'll kiss thy\n",
            "    hand\n",
            "    In sign o\"\n",
            ", I'll kiss thy\n",
            "    hand\n",
            "etbdoa\n",
            "ubt wLs ?loi'udT.tad\n",
            "as\n",
            "fy oieul,t\n",
            " rT\n",
            "s a \n",
            "csh\n",
            " o  ogbAoonlsola\n",
            "sosm\n",
            "sr\n",
            "oru.ebde\n",
            "CzCrw og?A T Ca \n",
            "gif\n",
            "rb\n",
            "e,hr elieo\n",
            "e  sD IWsbstduvB\n",
            "o blt,eorintsoiedeiitie b uoFetkE\n",
            "6250/6250 [==============================] - 36s 6ms/step - loss: 3.3284\n",
            "Epoch 2/10\n",
            "6250/6250 [==============================] - ETA: 0s - loss: 3.3177\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"roclamation that you are vanished.\n",
            "  PR\"\n",
            "roclamation that you are vanished.\n",
            "  PR,naoa y ehss,l menwsNeo  gethiCi,tio ta.eh\n",
            "kse.omm]? .tuoh it’wesci yioebteutl t,llY\n",
            "cha  onee  Wr]eiSs Loyh;noMretr?rE o. xeludi\n",
            "\n",
            " ad n  o uoe\n",
            "Raonestlcdeeai ilm LvhipartlmE  hnAa :aoc i\n",
            "opcsIo tCiyes I nhChtse a ih d sm ietn.r.lGotdeaa\n",
            "\n",
            "yowomt ,aeY\n",
            " t\n",
            "6250/6250 [==============================] - 36s 6ms/step - loss: 3.3177\n",
            "Epoch 3/10\n",
            "6248/6250 [============================>.] - ETA: 0s - loss: 3.3161\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"s wak’d with strife.\n",
            "\n",
            " [_Exeunt all bu\"\n",
            "s wak’d with strife.\n",
            "\n",
            " [_Exeunt all bu  Tees ingcore tlt vt  i   Obw]lt rj  ta obS\n",
            "nls o-osM osoY EtvohSew  . \n",
            "M I t\n",
            "AdIswBhsogr\n",
            "n \n",
            "t gni .uvthi\n",
            " a.cNeA nabfmNo \n",
            "rds\n",
            " okteu]eh,\n",
            "y e rB  hkt aow\n",
            "algEioUe\n",
            "s\n",
            "uete easf rn.c.Gbtsenpufrrl  oetB dlcDh,tsotyi sfhwn a\n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3161\n",
            "Epoch 4/10\n",
            "6250/6250 [==============================] - ETA: 0s - loss: 3.3149\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"Than my out-wall, open this purse, and t\"\n",
            "Than my out-wall, open this purse, and t   etrnne.te\n",
            "owd?\n",
            "'yrf m oeahelt n  fui  ea S ucrWh e Te  \n",
            "m niikwh   hifh fen., sres\n",
            "e e\n",
            "os\n",
            "OI !aoian\n",
            "uhslotfwD\n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3149\n",
            "Epoch 5/10\n",
            "6247/6250 [============================>.] - ETA: 0s - loss: 3.3141\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"ve you a soul or sense?\n",
            "God be wi’ you.\"\n",
            "ve you a soul or sense?\n",
            " ftrpean E,aihlose’os rl? Iukeac;srfn  t hAn\n",
            "s a\n",
            " yi pttoann  eaun\n",
            " Sfes\n",
            "T\n",
            "s te f etLd'ieoa,aHmohe yn—I eY  i aNsocsm et hWehmlfatnoltn \n",
            "\n",
            "c rhd eant t;nhine\n",
            " d mO  rnf , Wot me tkD  obalt\n",
            "rbIH  rokuA\n",
            "\n",
            "rG,g lHe ,hs actinoa    ,\n",
            "hod n    \n",
            "\n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3140\n",
            "Epoch 6/10\n",
            "6250/6250 [==============================] - ETA: 0s - loss: 3.3128\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"of the time.\n",
            "After your death you were \"\n",
            "of the time.\n",
            "After your death you were uF ’dl sreeEIfeamfe  tol rpoAIo\n",
            "\n",
            "r. d\n",
            "WtIo fhe msat\n",
            "t Cshtwwse  owr e ira lrra aaSabgIth\n",
            "irrrmoltgh a u lhw ;\n",
            "ETigciou\n",
            "eomLD EeS\n",
            "Wbtreinonta t r taaom odnpa.S O a Snraerodtbe\n",
            " i iRChaffrnc,raut\n",
            "dN\n",
            "eooeddeiBtFtSsei ue kn.etPtt\n",
            ", eNhm ttou a,rnary h n\n",
            "nhehdn eon\n",
            "aegmhndhollh\n",
            "ms\n",
            "6250/6250 [==============================] - 36s 6ms/step - loss: 3.3128\n",
            "Epoch 7/10\n",
            "6247/6250 [============================>.] - ETA: 0s - loss: 3.3118\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"ll feed on; but what is, come see,\n",
            "    \"\n",
            "ll feed on; but what is, come see,\n",
            "    etvy  a\n",
            "t\n",
            "R \n",
            " uh,hnse e   ohia r n luast atwc]o FriItSeoaC  c\n",
            "? o mttediiIeEksf A o.eema   Iu  auyschyerrrin  aysUH erAe.tOTft\n",
            "a eH'a mgoSleocgoSi   G fa   e\n",
            "t\n",
            "a j  r dBo  duMIei, r\n",
            "\n",
            "x’\n",
            "_concfp atosm \n",
            "\n",
            "leSow t\n",
            "Sslcms dkyh\n",
            "ac .i mhb  il t[ii\n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3118\n",
            "Epoch 8/10\n",
            "6246/6250 [============================>.] - ETA: 0s - loss: 3.3107\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"BURGUNDY. I am vanquished; these haughty\"\n",
            "BURGUNDY. I am vanquished; these haughtyr gLa httlfottoi   bennoytr as gwso.wbv olntsuBmdheeyerCwa s,snl o o wnt  Yi— nnaArvi'aTIfMl oe,notyr a dden h\n",
            "hT\n",
            "h Eas o;uDtlhLss l iudf uw  lyeI lu  i deMd-tYenNa r'aPs i \n",
            "\n",
            " sye   u \n",
            "r o lsbito asi xer\n",
            "uHa at stamsa   a elIow .?a  aE tritCoeo ed  \n",
            "d\n",
            "in,aeLu \n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3108\n",
            "Epoch 9/10\n",
            "6247/6250 [============================>.] - ETA: 0s - loss: 3.3100\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ick withal,\n",
            "To see great Hector in his \"\n",
            "ick withal,\n",
            " Lh'ei hs\n",
            "t eea ,u .hatniaIyao lm  tu no.srhrnlDy tod r os..fk  d, , memeei l sem\n",
            " wI s anfels\n",
            "ie.pevt  ah ns _ EI oisdiA ’o Y ;e ty  .yl   dt.aeia ed lsr  UAonto\n",
            "yewM \n",
            "hehe eayntnia tt\n",
            "TLoe,noae tIs \n",
            " vu't \n",
            "tydent   K d\n",
            "wB m\n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3100\n",
            "Epoch 10/10\n",
            "6240/6250 [============================>.] - ETA: 0s - loss: 3.3085\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \" held my stirrup,\n",
            "    Bareheaded plodde\"\n",
            " held my stirrup,\n",
            " i\n",
            " ervefhot IdlWrediheseF!.e apoiepu.  pe u.—c hrub detTl ea.egdgres\n",
            " \n",
            "snLLor aoy-tyNsnhdomst Is r\n",
            "\n",
            "Tl am\n",
            "eovhav\n",
            "   tJ\n",
            "T a blobg\n",
            "eegi,\n",
            " u.e\n",
            "r \n",
            "6250/6250 [==============================] - 37s 6ms/step - loss: 3.3087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa05b2de4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uxliX2Jz_wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiS4nsgUz_yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIOdBc1z_0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-jiArCuus6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}