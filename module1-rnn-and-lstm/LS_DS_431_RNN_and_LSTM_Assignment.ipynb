{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanCampos11/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM8ih8i_Yvre",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "kh5cfkXVYvrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "zBXBJxdzYvri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "id": "L5doYy1KYvrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5d69e3b0-d92b-4904-a212-4cd628d5e55d"
      },
      "source": [
        "\n",
        "df_toc.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 title  ...                                               text\n",
              "0  THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                       AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                 THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3            THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                            CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyMmu1xnlKtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f53e14c1-3570-4831-cc39-f2f8dfa040ef"
      },
      "source": [
        "data = df_toc['text'].values\n",
        "len(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c02n5XS7kjmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \" \".join(data)\n",
        "\n",
        "chars = list(set(text))\n",
        "\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKzk-cJQeANl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c381799-9edc-4314-ddb7-875e5476591d"
      },
      "source": [
        "maxlen = 40\n",
        "step = 5\n",
        "max_features = 20000\n",
        "batch_size = 32\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] \n",
        "next_char = []\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  3041161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRWnkW_2A0vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_size = 1800000\n",
        "sequences = [\n",
        "    sequences[i] for i in sorted(random.sample(range(len(sequences)), sample_size))\n",
        "]\n",
        "# sequences = random.sample(sequences,2000000)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzY4LEkuuia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QequjCwax0F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSbziohxzLTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, sequences in enumerate(sequences):\n",
        "    for t, char in enumerate(sequences):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbSblnhzRi6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34d62239-6737-4a70-c90f-1ab6b9990fe3"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD45JvI7uulW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(106, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdThFl2euuqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjMSZGVoz_rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSGNDwOcz_t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18a2971f-1977-451d-a49a-085ddd3be41e"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=30,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "56249/56250 [============================>.] - ETA: 0s - loss: 3.3015\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"elight;\n",
            "  Which seen, her eyes, as murd\"\n",
            "elight;\n",
            "  Which seen, her eyes, as murdnvnst otrueogA   tr  w ess \n",
            "yonsahynenuFE.et\n",
            "tw 'hgO o\n",
            "ittp soss\n",
            "nRtkE,v a\n",
            " tf riaIhNhhitro o l isom,cnha  CN hGhw \n",
            "OanoEmwers\n",
            " Tllo  oe S  yedO,na\n",
            " \n",
            "NmfnyTaa esscIyF\n",
            "eduLtY r e\n",
            " oienLtn'msneadI  Sh eh h\n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.3015\n",
            "Epoch 2/30\n",
            "56249/56250 [============================>.] - ETA: 0s - loss: 3.2984\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \".\n",
            "\n",
            "AUTOLYCUS.\n",
            "[_Aside._] Though I am \"\n",
            ".\n",
            "\n",
            "AUTOLYCUS.\n",
            "[_Aside._] Though I am  gClv  .l iroRshLotuasNu \n",
            "lt en\n",
            "y. y\n",
            "\n",
            "paU g rb,rrlBrirl,i aatg,l\n",
            "oNftmg tUtoyl toa h\n",
            "cvah\n",
            "WtAlryOisaco\n",
            "\n",
            "rh ., Trsoi b.Ai eu lpFe rh  \n",
            ".\n",
            "e omg ,Slutd scW, ati,r lusAuprcNRnws: eofdcpm  he\n",
            ".o ilfE\n",
            "  er nt thej \n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2984\n",
            "Epoch 3/30\n",
            "56244/56250 [============================>.] - ETA: 0s - loss: 3.2980\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"thee,\n",
            "The more I have, for both are inf\"\n",
            "thee,\n",
            "The more I have, for both are infaOca,\n",
            "r g i ayhy eeo w dwo\n",
            "ul rn\n",
            "odry\n",
            "enhkhudldmo  .itt yae We vnvfohfteoh\n",
            "\n",
            "e a l  drt ei\n",
            "an.\n",
            "or\n",
            "\n",
            "   oriftdos\n",
            "i mtl o aESb \n",
            "heeigod, uinoh\n",
            ",cSnhne,tmid casieicetenrt.\n",
            "tt e\n",
            "od\n",
            "oF\n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2980\n",
            "Epoch 4/30\n",
            "56246/56250 [============================>.] - ETA: 0s - loss: 3.2977\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"at wide gap, since it is in my power\n",
            "To\"\n",
            "at wide gap, since it is in my power\n",
            "ni r .teThv  emn rthoe  ItU  Wku\n",
            "eRoeeabrmrMtaENe rtenl rir tff,s, u,e s  eSv diRro oaeae yyI v   ,do\n",
            " h\n",
            "rT lleae :lt or ur  'eep eou un   fc \n",
            " tIl rEh  \n",
            "sst\n",
            "vrptsg\n",
            "t CW  Taa C\n",
            " W\n",
            " w suu tdrcqs Ir  do.so  r\n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2977\n",
            "Epoch 5/30\n",
            "56249/56250 [============================>.] - ETA: 0s - loss: 3.2998\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"and his TUTOR\n",
            "\n",
            "  RUTLAND. Ah, whither \"\n",
            "and his TUTOR\n",
            "\n",
            "  RUTLAND. Ah, whither ioi\n",
            "ofT .soNHs,frnicngahwporre  deeneh rnyi  oFth  E  at;ScAa iueoo priE.yf\n",
            "\n",
            " Howtrr  nntAtlw\n",
            " tnho saltotf \n",
            "ti re eiatHya Ocnst edIttvhkh\n",
            "\n",
            "dgh \n",
            "N \n",
            "age ,et uu,emkkh c b_asenr In  \n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2998\n",
            "Epoch 6/30\n",
            "56250/56250 [==============================] - ETA: 0s - loss: 3.2972\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"d; and having the world for\n",
            "your labour\"\n",
            "d; and having the world for\n",
            "your labourkesu\n",
            "w\n",
            "betoc \n",
            " beSht i h nt rrt idi\n",
            "UmetKU d\n",
            "csgt \n",
            "rdr hr rpbahmdSaw\n",
            ".y o es\n",
            "Lh A,D  \n",
            "tY-a ue  'mman hIbu\n",
            "Au  \n",
            "oail. lMryAl n\n",
            "fynz  dg dprntrrirA CynpjRn ba\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2972\n",
            "Epoch 7/30\n",
            "56244/56250 [============================>.] - ETA: 0s - loss: 3.2969\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"th of the Count’s\n",
            "was today with my lad\"\n",
            "th of the Count’s\n",
            " onoR  ,y  u tiee i. Ta‘ndkanLme\n",
            "laa’tmI e dlu\n",
            "\n",
            "m , etILo f m ir h o d tohSSd oiE  thee\n",
            "eo  m \n",
            "yee   shhtW\n",
            "aOstof'anhw\n",
            "paoa  unl epaitdsl tt ow  o   AM r   o\n",
            "ur hlhf oeowGy g hljmtt saedp , e hu.\n",
            "Hrahuub ihrbh et lmgnh,   .tr nsuda ouero  u , tntnvlhm\n",
            "ls S aa ererA t \n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2969\n",
            "Epoch 8/30\n",
            "56245/56250 [============================>.] - ETA: 0s - loss: 3.2985\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \".\n",
            "\n",
            "DESDEMONA.\n",
            "Let’s meet him, and rec\"\n",
            ".\n",
            "\n",
            "DESDEMONA.\n",
            "Let’s meet him, and recWT  he rv’r ssedisbi  ,\n",
            "t nt  em dhI SDisn.tree t nartiosel[i p\n",
            "do ai aPbftio. eoolgsifd  \n",
            "seuea  A dt r s l\n",
            "reWt sabwnnripa t..el \n",
            "nut DbehtsOhvo  itPniEg,sn oLaol ee \n",
            "tt m mnTvginw w.tdCsthishyDekn .W\n",
            "Cr\n",
            ", tnnpel \n",
            "\n",
            " \n",
            "r eoufyt.k \n",
            "56250/56250 [==============================] - 224s 4ms/step - loss: 3.2985\n",
            "Epoch 9/30\n",
            "56248/56250 [============================>.] - ETA: 0s - loss: 3.2973\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"I had rather pray a month with mutton an\"\n",
            "rlrhnu otIpts MemE R ,fww\n",
            "oucA g.hk ro!uulu U eaahdaa,\n",
            " \n",
            ";hRIyO g o.tLyr,swdo o\n",
            "Sdhle\n",
            "tn ,la   Jt  ahsrae u arnC,. dyftEtl \n",
            "Bo\n",
            "fuoIft  resn, eMwiyatP hk\n",
            "sA\n",
            "56250/56250 [==============================] - 228s 4ms/step - loss: 3.2973\n",
            "Epoch 10/30\n",
            "56242/56250 [============================>.] - ETA: 0s - loss: 3.2962\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"erefore he hates me.\n",
            "\n",
            "SALARINO.\n",
            "I am \"\n",
            "erefore he hates me.\n",
            "\n",
            "SALARINO.\n",
            "l. uuahye ehrh e t ruT\n",
            "c r rr\n",
            "lehrxador\n",
            "\n",
            " pnngsBltrtedn i d oa\n",
            "iyr\n",
            "nrY.k  E\n",
            "e no\n",
            "\n",
            "c at a nhn\n",
            " l\n",
            " he vta due,emlroi  dsUeele  ekhel\n",
            ", nmtt \n",
            "dnao  u\n",
            "me T h  o.y ea  \n",
            "Le\n",
            " a\n",
            "oaunant\n",
            "h tInsmla]wTts\n",
            "mhils nAauloiol hsea\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2962\n",
            "Epoch 11/30\n",
            "56246/56250 [============================>.] - ETA: 0s - loss: 3.2953\n",
            "----- Generating text after Epoch: 10\n",
            "----- Generating with seed: \"shall she be fourteen.\n",
            "Susan and she,—G\"\n",
            "shall she be fourteen.\n",
            "\n",
            "arel;kIeunidsah? h \n",
            " b hs ais.lsbtitt.n  e a y tGTwu\n",
            "\n",
            "itapf\n",
            "rl\n",
            "eihmor,  s  \n",
            "niT.omyENluhg u' h\n",
            "culO,lq w ]sEoa mhsso\n",
            "56250/56250 [==============================] - 225s 4ms/step - loss: 3.2953\n",
            "Epoch 12/30\n",
            "56243/56250 [============================>.] - ETA: 0s - loss: 3.2947\n",
            "----- Generating text after Epoch: 11\n",
            "----- Generating with seed: \"n._] What’s all the doors open here?\n",
            "\n",
            "\"\n",
            "n._] What’s all the doors open here?\n",
            "\n",
            " siesreao vsIA  AM e\n",
            "  doie n _eeuhea f Aea.teao  toe e\n",
            " uoPr r alort sabltkstuat a.o ei I' [n ht alae  bd“ ImMvomb I i oyt,oi  uudhsIa Oohheu\n",
            "lecen s,arr trrg,eteh?, Tr\n",
            "Bgwo\n",
            "ob  r\n",
            " sd Gnwlm\n",
            "Rutyaanlen   y vr\n",
            "n e\n",
            "p\n",
            "uersrhg yd lee mfy al\n",
            "elr\n",
            "56250/56250 [==============================] - 228s 4ms/step - loss: 3.2947\n",
            "Epoch 13/30\n",
            "56245/56250 [============================>.] - ETA: 0s - loss: 3.2941\n",
            "----- Generating text after Epoch: 12\n",
            "----- Generating with seed: \"the beast liv’d, was kill’d with hunting\"\n",
            "the beast liv’d, was kill’d with hunting Lar mydTa\n",
            "eethietc h.  ntU \n",
            "T\n",
            "n a  hv n \n",
            "aoyslt A,hs.esee,f ;Sot \n",
            " a tEftR \n",
            "gh hTiIst\n",
            "h adNeh t\n",
            "wT —\n",
            "e,,e, y[hmhtshWwnMi i\n",
            "dwsinpwK;hrisihTi ehh e  sliianr\n",
            "hom\n",
            "dw ehreonw,tEeih\n",
            "pcE o rt  t u  anb sdl e\n",
            "of  \n",
            "hea t,e'\n",
            "nab,n mo ts t e t\n",
            " yM\n",
            "56250/56250 [==============================] - 228s 4ms/step - loss: 3.2941\n",
            "Epoch 14/30\n",
            "56240/56250 [============================>.] - ETA: 0s - loss: 3.2934\n",
            "----- Generating text after Epoch: 13\n",
            "----- Generating with seed: \"ly for thy mistress' sake,\n",
            "    That us'\"\n",
            "ly for thy mistress' sake,\n",
            "    That us'fr ta;\n",
            "-bUD   ig ype   T at\n",
            "gpoe .r Dtta;!o oCes\n",
            "te,nKU,ore\n",
            " m ls\n",
            "sf\n",
            "’erpt sCelrtheo\n",
            " T  wobhwR.fm  Apoe w ,el!ge\n",
            "W.nethtdnm,eeeusb ehlpct,ve   rfmceyoiruwt ret a m  \n",
            "rf   omrlmao ,pha\n",
            "o hn\n",
            "mhvoeo gCeenhf\n",
            "s!wetco\n",
            "eHS ;nhA:nam.t\n",
            "56250/56250 [==============================] - 228s 4ms/step - loss: 3.2934\n",
            "Epoch 15/30\n",
            "56242/56250 [============================>.] - ETA: 0s - loss: 3.2926\n",
            "----- Generating text after Epoch: 14\n",
            "----- Generating with seed: \"\n",
            "To know the reason of this strange rest\"\n",
            "\n",
            "oe Aws \n",
            "  R o,f   a ddj.r aitI,dm sdI hih f o a  \n",
            "aemi s  sleg ,an l’. n ueil s e o \n",
            "ent.dattwfhytst   N\n",
            "nss  ai rrvYoosd tottw o!Nembr ra e  s. t  w bns.\n",
            "  . dycc hS t IaoN\n",
            ",so\n",
            "atll onY n\n",
            " nom\n",
            "td yl es\n",
            "e eosnu.ealnanan rh‘t\n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2926\n",
            "Epoch 16/30\n",
            "56248/56250 [============================>.] - ETA: 0s - loss: 3.2916\n",
            "----- Generating text after Epoch: 15\n",
            "----- Generating with seed: \"ord.\n",
            "\n",
            "CAPULET.\n",
            "Hang thee young baggag\"\n",
            "ord.\n",
            "\n",
            "CAPULET.\n",
            "dnv ie\n",
            "\n",
            "oac[ha \n",
            " v  .YouGeRn o ’Oo'LHag e\n",
            "K,ynlre  TT\n",
            "c   iseadot e\n",
            "a he d e't,teatete\n",
            "neg.Aot\n",
            "erou,belt\n",
            "56250/56250 [==============================] - 229s 4ms/step - loss: 3.2916\n",
            "Epoch 17/30\n",
            "56250/56250 [==============================] - ETA: 0s - loss: 3.2906\n",
            "----- Generating text after Epoch: 16\n",
            "----- Generating with seed: \" here againe, and there againe: ha,\n",
            "Boy\"\n",
            " here againe, and there againe: ha,\n",
            "Boy'f\n",
            "rod  p’\n",
            "syytodSniIit \n",
            " ne o    c  tAthUa Hsn\n",
            "rneo [wb\n",
            " \n",
            "e te  l ,eedv\n",
            "uOIaeet \n",
            " Ls pae'sndevbcth hi geo tN  fLcutn Wna \n",
            "r\n",
            "lohne nonthfrni fihc hE aa roe\n",
            " nletti.m i i,  e\n",
            "rn\n",
            "eddeo  eiwdoM  \n",
            "56250/56250 [==============================] - 229s 4ms/step - loss: 3.2906\n",
            "Epoch 18/30\n",
            "56248/56250 [============================>.] - ETA: 0s - loss: 3.2891\n",
            "----- Generating text after Epoch: 17\n",
            "----- Generating with seed: \"ch slop. You\n",
            "gave us the counterfeit fa\"\n",
            "ch slop. You\n",
            "gave us the counterfeit fa \n",
            " m\n",
            "egs  ti eort \n",
            "cw. ldv  t  s  miC\n",
            "l vseag    Nhniie nd_eer  r o-neeuBri n r ,.esSea\n",
            " l tsn gen\n",
            "eesinc ,a oog owzch  dt rUitoredTe’opTu  tNh  MO Blwg rfeldosnh,a\n",
            "  henea h . htryre t EtAuf!.tdtity EtE\n",
            " e  te  f;s,sOhE anhfa ntw ih\n",
            "  m ehoHd  s\n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2892\n",
            "Epoch 19/30\n",
            "56248/56250 [============================>.] - ETA: 0s - loss: 3.2887\n",
            "----- Generating text after Epoch: 18\n",
            "----- Generating with seed: \"   Has desp'rate want made!\n",
            "    What vi\"\n",
            "   Has desp'rate want made!\n",
            "    What viatir,npy ams\n",
            ".,lpt slunrhr ioui\n",
            " diii\n",
            "  tnw l,;  uuIe hoeFuyey.  ta HihhUsd trhy pfuht lwuh ro leeiosm\n",
            "nMat  le\n",
            "tihne to r’roism,E\n",
            "h ts Hr i ns\n",
            "sMhe ngTs i rls . r\n",
            "\n",
            "y\n",
            "ue  hpW Ft’r oe xaW eenn uso  .ec er a'Fp  rw oharI ntlnhhemu uu   htraoTpn wf eUew]bC tTmTtuhyho Rsrkee  t \n",
            "56250/56250 [==============================] - 223s 4ms/step - loss: 3.2887\n",
            "Epoch 20/30\n",
            "56242/56250 [============================>.] - ETA: 0s - loss: 3.2875\n",
            "----- Generating text after Epoch: 19\n",
            "----- Generating with seed: \"he knew\n",
            "What houre my fit would take me\"\n",
            "he knew\n",
            "What houre my fit would take mev , o ca hsai gesutnoek\n",
            "nit ti a h n  alae\n",
            "l\n",
            "lr\n",
            "Lew stdl tn lp yntmlishooeidphaaiehr     ufd\n",
            " tlsbght rf aTdl yd\n",
            "I dres otLhRl!do\n",
            "n\n",
            "lr\n",
            "dr ’Se a,hi\n",
            " e ge ;r'fe lb vtGh ’frs\n",
            "tp ghmni:\n",
            "ou  l  na   e t\n",
            "m eisa \n",
            "iqo\n",
            "t\n",
            "56250/56250 [==============================] - 225s 4ms/step - loss: 3.2875\n",
            "Epoch 21/30\n",
            "56243/56250 [============================>.] - ETA: 0s - loss: 3.2864\n",
            "----- Generating text after Epoch: 20\n",
            "----- Generating with seed: \"otions and the motions. Shall I\n",
            "    los\"\n",
            "otions and the motions. Shall I\n",
            ";a oose.d, t rybsne\n",
            "G.dww y ce eo  ot  opaerTttagnlr hl shfFk Te, iarmhheeyea\n",
            "\n",
            "sekhdTe rm\n",
            "d Lg tphwNhdmpaC hh lhte . doenWoiih sfis eu aesu t e HieErtgtelre ;t\n",
            "cdo\n",
            "Bg. ama.yncl nA fsImts t heptr.dImdect he t e  Sjefr,eEMei h\n",
            "56250/56250 [==============================] - 228s 4ms/step - loss: 3.2864\n",
            "Epoch 22/30\n",
            "56246/56250 [============================>.] - ETA: 0s - loss: 3.2856\n",
            "----- Generating text after Epoch: 21\n",
            "----- Generating with seed: \"high respect. Thither Macduff\n",
            "Is gone t\"\n",
            "high respect. Thither Macduff\n",
            "Is gone t\n",
            "v\n",
            " uruI hbn\n",
            "hset\n",
            "t \n",
            "gSeI rnmhr r\n",
            "nAyor UEbtSle ete\n",
            "o e r, ra Jek stnrAhAn,utvsr lsS tutgrdNiy haclo\n",
            "l tuddoar\n",
            "\n",
            "e niaaRilh\n",
            "e lnCe_u\n",
            " p awmml \n",
            "a\n",
            " ar?uhEA  d.ir cnudelivn\n",
            "ahflI  oefs boeEdAor ’ds!,wo aoEa\n",
            "i nanlh n\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2856\n",
            "Epoch 23/30\n",
            "56249/56250 [============================>.] - ETA: 0s - loss: 3.2847\n",
            "----- Generating text after Epoch: 22\n",
            "----- Generating with seed: \"; if you tarry longer\n",
            "I shall give wors\"\n",
            "; if you tarry longer\n",
            "I shall give wors:eo\n",
            "era\n",
            "a\n",
            "AH;He ae\n",
            "hhF.\n",
            "  d;;Tssolyie   ul riKs, hhehs\n",
            "eoe Cn ms.dtie\n",
            " nh , ecyce f\n",
            " o?O,d rt rndm H toEc.hF trli oAhe  t os.c\n",
            "r teo Yda \n",
            "dd ,yaealeaAe Wcd t\n",
            "orwinI ITd_a  ?\n",
            "eeuoEtl , dm \n",
            "bmeo o de \n",
            "SoUL,rrhPsse ’naRitnc suRonAp s t  Iv\n",
            "56250/56250 [==============================] - 225s 4ms/step - loss: 3.2847\n",
            "Epoch 24/30\n",
            "56250/56250 [==============================] - ETA: 0s - loss: 3.2838\n",
            "----- Generating text after Epoch: 23\n",
            "----- Generating with seed: \"\n",
            "And deep-brain’d sonnets that did ampl\"\n",
            "\n",
            "dalI etdternotm t l’TTep?oiasps!c\n",
            " hlNsk c\n",
            " e\n",
            "u sr e,Wamis y RmS ddeF aeGsioe i nBeiesIarvltE. Li  As asngh\n",
            "fm,ROePos\n",
            "o dsl,c u uotR hoseesoG.Whhtnyldyv ae\n",
            "i no fjitetnuv   en  oto arteor  ee Du  lte\n",
            "sy elAernl eeia\n",
            "mi fbhy.YTo  sLu o      c s g \n",
            "56250/56250 [==============================] - 227s 4ms/step - loss: 3.2838\n",
            "Epoch 25/30\n",
            "56250/56250 [==============================] - ETA: 0s - loss: 3.2830\n",
            "----- Generating text after Epoch: 24\n",
            "\"\n",
            " pioetitl.f\n",
            "a toee_ia\n",
            "aA' fesPuvse\n",
            "ndIa \n",
            "\n",
            "iA\n",
            " ,f  W  slTs udlh \n",
            "a au\n",
            "wnmidr\n",
            " tstrt dI  hyO \n",
            "s  tnwixh_oi u\n",
            " gSapsn gs? hA,hBw U.s\n",
            "56250/56250 [==============================] - 229s 4ms/step - loss: 3.2830\n",
            "Epoch 26/30\n",
            "56239/56250 [============================>.] - ETA: 0s - loss: 3.2830\n",
            "----- Generating text after Epoch: 25\n",
            "----- Generating with seed: \"and leaps down within it._]\n",
            "\n",
            " Enter Be\"\n",
            "and leaps down within it._]\n",
            "\n",
            " Enter Bep .E \n",
            "nIno\n",
            "efyeeult s \n",
            "w aa\n",
            "ttt  k TA sd. renot sw nhp\n",
            "lrteh.yieahE eismkdu mttenntroti,rwr\n",
            "tIet\n",
            "wr    t s\n",
            "   c, l s?serd\n",
            "ttwp\n",
            " F o\n",
            "lnShoteRa  Au n toebveunrnreo\n",
            "\n",
            "tiit c uOs  nahd \n",
            "h lhmbnyKo    xtCs \n",
            "n Ut a\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2830\n",
            "Epoch 27/30\n",
            "56246/56250 [============================>.] - ETA: 0s - loss: 3.2831\n",
            "----- Generating text after Epoch: 26\n",
            "----- Generating with seed: \"venly Lymiter pleases.\n",
            "\n",
            "PALAMON.\n",
            "You \"\n",
            "venly Lymiter pleases.\n",
            "\n",
            "PALAMON.\n",
            " h eytaeo  eTu \n",
            "shidseh\n",
            "nb yme  oal oac a\n",
            "  igv us K b,   di oootmreitl eUnroy;o l\n",
            "toa\n",
            "isms  e  T?M,yh\n",
            "Y rl, r eh\n",
            "i e Deeap]rar\n",
            ".\n",
            " v\n",
            "o.\n",
            " ur lTdioEMe  I  tnhc\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2831\n",
            "Epoch 28/30\n",
            "56246/56250 [============================>.] - ETA: 0s - loss: 3.2834\n",
            "----- Generating text after Epoch: 27\n",
            "----- Generating with seed: \"and to, and feed,\n",
            "Although my last, no \"\n",
            "and to, and feed,\n",
            "fhetud o oe\n",
            "o.kGh fsoisl  uIAtsUraEhet._I  oT mne\n",
            "n syoeeoeNnie lL\n",
            "ohiClfLao’ .gdberia\n",
            "  . cfmce  eoarK,l rtrie.r. nQIsnhuoeonaeWllnaIlyUn eo etatt oxa\n",
            "l rAshN n  or smsy\n",
            "nrd\n",
            "’A \n",
            "pt se oaTtAl eela ubAaP, GTi YIuol aen\n",
            "aglie isrsc p ePs w\n",
            "sruo Due iliOE\n",
            "l \n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2835\n",
            "Epoch 29/30\n",
            "56250/56250 [==============================] - ETA: 0s - loss: 3.2939\n",
            "----- Generating text after Epoch: 28\n",
            "----- Generating with seed: \"led me brother; and then the two\n",
            "kings \"\n",
            "led me brother; and then the two\n",
            "kings omlso'n\n",
            "tI oOoh nR .i\n",
            " llD?  aw  ue\n",
            ":e:\n",
            "gn Tor\n",
            "pd \n",
            "iA \n",
            "Eg\n",
            "rleara yoTaIweni nt\n",
            " tgeoo evbKwnOmhkoincaruEfensw,\n",
            "\n",
            "l et  ov\n",
            "yefhir srk h.t\n",
            "lule o\n",
            "56250/56250 [==============================] - 226s 4ms/step - loss: 3.2939\n",
            "Epoch 30/30\n",
            "56241/56250 [============================>.] - ETA: 0s - loss: 3.3399\n",
            "----- Generating text after Epoch: 29\n",
            "----- Generating with seed: \"e he fights on Galathe his horse,\n",
            "And t\"\n",
            "e he fights on Galathe his horse,\n",
            "yi Rssi ie\n",
            "OndE\n",
            "uullep\n",
            "l\n",
            "\n",
            "[id"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ze_ldt;y ief llA\n",
            "hl h nt .r'yfi oBha  n ohphe ,edit .r nkhso iTt tbuop.eI r moheg \n",
            " o i\n",
            "fSaet. \n",
            "Ci\n",
            " m oo\n",
            "56250/56250 [==============================] - 225s 4ms/step - loss: 3.3398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34a002ba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uxliX2Jz_wI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiS4nsgUz_yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIOdBc1z_0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR-jiArCuus6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}